{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb73dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3106cf8",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5996ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据所在文件夹\n",
    "base_dir=\"E:\\\\猫狗分类数据\"\n",
    "train_dir=os.path.join(base_dir,'train_dir')\n",
    "validation_dir=os.path.join(base_dir,'validation')\n",
    "\n",
    "#训练集\n",
    "train_cats_dir=os.path.join(train_dir,'train_cat')\n",
    "train_dogs_dir=os.path.join(train_dir,'train_dog')\n",
    "\n",
    "\n",
    "#验证集\n",
    "validation_cats_dir=os.path.join(validation_dir,'cats')\n",
    "validation_dogs_dir=os.path.join(validation_dir,'dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d309ed3",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c5747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23439 images belonging to 2 classes.\n",
      "Found 1561 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                    (64,64),\n",
    "                                                    batch_size=100,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir, \n",
    "                                                              (64, 64), \n",
    "                                                              batch_size=100,\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0de23f",
   "metadata": {},
   "source": [
    "#数据增强 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbbbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67263850",
   "metadata": {},
   "source": [
    "# 构建卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0eab8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 504,001\n",
      "Trainable params: 504,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8a860e",
   "metadata": {},
   "source": [
    "# 配置训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20031530",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-4), \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b51ea5",
   "metadata": {},
   "source": [
    "# 训练网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f73e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "230/230 [==============================] - 138s 598ms/step - loss: 0.6753 - acc: 0.5778 - val_loss: 0.6990 - val_acc: 0.5280\n",
      "Epoch 2/15\n",
      "230/230 [==============================] - 71s 307ms/step - loss: 0.6464 - acc: 0.6199 - val_loss: 0.5656 - val_acc: 0.7353\n",
      "Epoch 3/15\n",
      "230/230 [==============================] - 68s 293ms/step - loss: 0.6225 - acc: 0.6488 - val_loss: 0.5522 - val_acc: 0.7333\n",
      "Epoch 4/15\n",
      "230/230 [==============================] - 73s 315ms/step - loss: 0.5978 - acc: 0.6721 - val_loss: 0.5631 - val_acc: 0.7133\n",
      "Epoch 5/15\n",
      "230/230 [==============================] - 72s 312ms/step - loss: 0.5696 - acc: 0.7002 - val_loss: 0.5059 - val_acc: 0.7740\n",
      "Epoch 6/15\n",
      "230/230 [==============================] - 72s 311ms/step - loss: 0.5477 - acc: 0.7213 - val_loss: 0.5224 - val_acc: 0.7487\n",
      "Epoch 7/15\n",
      "230/230 [==============================] - 72s 311ms/step - loss: 0.5289 - acc: 0.7360 - val_loss: 0.5877 - val_acc: 0.6767\n",
      "Epoch 8/15\n",
      "230/230 [==============================] - 69s 300ms/step - loss: 0.5105 - acc: 0.7515 - val_loss: 0.4557 - val_acc: 0.7993\n",
      "Epoch 9/15\n",
      "230/230 [==============================] - 70s 306ms/step - loss: 0.4958 - acc: 0.7584 - val_loss: 0.4667 - val_acc: 0.7860\n",
      "Epoch 10/15\n",
      "230/230 [==============================] - 71s 309ms/step - loss: 0.4812 - acc: 0.7679 - val_loss: 0.4466 - val_acc: 0.8000\n",
      "Epoch 11/15\n",
      "230/230 [==============================] - 73s 319ms/step - loss: 0.4655 - acc: 0.7781 - val_loss: 0.5360 - val_acc: 0.7220\n",
      "Epoch 12/15\n",
      "230/230 [==============================] - 68s 295ms/step - loss: 0.4474 - acc: 0.7913 - val_loss: 0.4347 - val_acc: 0.8073\n",
      "Epoch 13/15\n",
      "230/230 [==============================] - 69s 300ms/step - loss: 0.4365 - acc: 0.7981 - val_loss: 0.4114 - val_acc: 0.8233\n",
      "Epoch 14/15\n",
      "230/230 [==============================] - 70s 303ms/step - loss: 0.4223 - acc: 0.8050 - val_loss: 0.5205 - val_acc: 0.7420\n",
      "Epoch 15/15\n",
      "230/230 [==============================] - 68s 296ms/step - loss: 0.4085 - acc: 0.8139 - val_loss: 0.3992 - val_acc: 0.8287\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=230,\n",
    "    epochs=15, \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=15,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907f96fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ebaad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
